{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Revision of SML_miniproj_LogisticRegression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#IMPORTANT RUN AT START\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.stats as stats\n",
        "import math\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import sklearn.model_selection as skl_ms\n",
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "9YJFLI62QAbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "getting data"
      ],
      "metadata": {
        "id": "2OFF9Vji7HEc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zAy5BN0xPz5U"
      },
      "outputs": [],
      "source": [
        "url = 'https://raw.githubusercontent.com/Ari-vu/SML/main/Given_data/train.csv'\n",
        "df = pd.read_csv(url)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting test and train data sets"
      ],
      "metadata": {
        "id": "4AsVH1-77N61"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split train and test data\n",
        "  # percentage of training data to be used in training set\n",
        "perc = 0.70\n",
        "  #setting random state for consistency\n",
        "random_state = 10\n",
        "np.random.seed(random_state) # \n",
        "  #using numpy to randomy select 70% of total data for training data set\n",
        "trainIndex = np.random.choice(df.shape[0], size=int(perc*df.shape[0]), replace=False)\n",
        "train = df.iloc[trainIndex]\n",
        "  #remaining data assigned to test set\n",
        "test = df.iloc[~df.index.isin(trainIndex)]"
      ],
      "metadata": {
        "id": "WC8nVBqleQwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting X and Y from test and train sets\n",
        "  #train data splitting\n",
        "X_train = train.drop(columns=['Lead'])\n",
        "Y_train = train['Lead']\n",
        "  #reshaping y to be accepted by fit operator\n",
        "Y_train_np = np.ravel(Y_train,order='C')\n",
        "  #test data splitting\n",
        "X_test = test.drop(columns=['Lead'])\n",
        "Y_test = test['Lead']"
      ],
      "metadata": {
        "id": "D9kgqyoQtg1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "preprocessing data by Normalising"
      ],
      "metadata": {
        "id": "YU47YbND7Q2C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "norm = MinMaxScaler().fit(X_train)\n",
        "X_train_norm = norm.transform(X_train)\n",
        "X_test_norm = norm.transform(X_test)"
      ],
      "metadata": {
        "id": "00FGkzaAQJzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Choosing best solver \n",
        "  #appending solver algorithms to be tested to iterable\n",
        "solver=[]\n",
        "\n",
        "solver.append(LogisticRegression(solver='newton-cg', random_state=1,max_iter= 200))\n",
        "solver.append(LogisticRegression(solver='lbfgs', random_state=1,max_iter= 200))\n",
        "solver.append(LogisticRegression(solver='liblinear', random_state=1,max_iter= 200))\n",
        "solver.append(LogisticRegression(solver='sag', random_state=1,max_iter= 200))\n",
        "solver.append(LogisticRegression(solver='saga', random_state=1,max_iter= 200))"
      ],
      "metadata": {
        "id": "lpOOiOWaAdrf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#solving and testing accuracy of algorithms\n",
        "for i in range((np.shape(solver)[0])):\n",
        "  solve = solver[i]\n",
        "  solve.fit(X_train_norm,Y_train_np)\n",
        "  Y_pred=solve.predict(X_test_norm)\n",
        "  print(solver[i])\n",
        "  acc = metrics.accuracy_score(Y_test, Y_pred)\n",
        "  print(acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7B0Ald5Kvxa",
        "outputId": "42c82176-4b9c-42db-98f5-6b30aa8c77c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression(max_iter=200, random_state=1, solver='newton-cg')\n",
            "0.8205128205128205\n",
            "LogisticRegression(max_iter=200, random_state=1)\n",
            "0.8205128205128205\n",
            "LogisticRegression(max_iter=200, random_state=1, solver='liblinear')\n",
            "0.8237179487179487\n",
            "LogisticRegression(max_iter=200, random_state=1, solver='sag')\n",
            "0.8205128205128205\n",
            "LogisticRegression(max_iter=200, random_state=1, solver='saga')\n",
            "0.8205128205128205\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression algorithm Liblinear is chosen as it has highest accuracy"
      ],
      "metadata": {
        "id": "3mOPdLxY7V--"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tuning hyperparameters for Liblinear"
      ],
      "metadata": {
        "id": "c1N1PuVGOdrV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# setting parameters to be tuned by gridsearch\n",
        "  # liblinear supports l1 and l2 regularisation\n",
        "penalty = ['l1','l2']\n",
        "  # strength of regularisation to be used\n",
        "C = np.linspace(0.1, 300, 100)\n",
        "  # intercept term\n",
        "intercept = [True,False]\n",
        "\n",
        "  #setting up variables for gridsearch\n",
        "grid_logReg ={'penalty': penalty, 'C': C, 'fit_intercept': intercept}\n",
        "\n",
        "solver = LogisticRegression(max_iter=200, random_state=1, solver='liblinear')\n"
      ],
      "metadata": {
        "id": "Z07glOgzOcSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating and fitting logistic regression grid\n",
        "model = skl_ms.GridSearchCV(estimator=solver, param_grid = grid_logReg )\n",
        "\n",
        "model.fit(X_train_norm,Y_train_np)"
      ],
      "metadata": {
        "id": "rKeyTaunM7Lh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "939ab47f-5aa0-4388-811c-460fb3beb1e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(estimator=LogisticRegression(max_iter=200, random_state=1,\n",
              "                                          solver='liblinear'),\n",
              "             param_grid={'C': array([1.00000000e-01, 3.12929293e+00, 6.15858586e+00, 9.18787879e+00,\n",
              "       1.22171717e+01, 1.52464646e+01, 1.82757576e+01, 2.13050505e+01,\n",
              "       2.43343434e+01, 2.73636364e+01, 3.03929293e+01, 3.34222222e+01,\n",
              "       3.64515152e+01, 3.94808081e+01, 4.25101010e+01, 4.55393939e+...\n",
              "       2.42443434e+02, 2.45472727e+02, 2.48502020e+02, 2.51531313e+02,\n",
              "       2.54560606e+02, 2.57589899e+02, 2.60619192e+02, 2.63648485e+02,\n",
              "       2.66677778e+02, 2.69707071e+02, 2.72736364e+02, 2.75765657e+02,\n",
              "       2.78794949e+02, 2.81824242e+02, 2.84853535e+02, 2.87882828e+02,\n",
              "       2.90912121e+02, 2.93941414e+02, 2.96970707e+02, 3.00000000e+02]),\n",
              "                         'fit_intercept': [True, False],\n",
              "                         'penalty': ['l1', 'l2']})"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ouput best parameters . best score is accuracy \n",
        "print('Best Score :', model.best_score_)\n",
        "print('Best Parameters :',model.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3aeuFj23Xhr6",
        "outputId": "ce4c0605-f32a-4747-ae80-aa4960ff4c9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Score : 0.8707132735002361\n",
            "Best Parameters : {'C': 72.8030303030303, 'fit_intercept': True, 'penalty': 'l1'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# setting parameter variables using results from gridsearch\n",
        "para_intercept = model.best_params_['fit_intercept']\n",
        "para_penalty = model.best_params_['penalty']"
      ],
      "metadata": {
        "id": "nRrG0pfjd20b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "investigating further tuning options"
      ],
      "metadata": {
        "id": "5JNi2nsdZeGt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# refining C parameter value based in n-1 and n+1 range \n",
        "C2 = np.linspace(69,75, 50)\n",
        "# intercept scaling parameter defaul =1 \n",
        "int_scale = np.linspace(0.1,2, 20)\n",
        "# setting up variables for new gridsearch\n",
        "grid_logReg_2 ={'C': C2, 'intercept_scaling': int_scale}\n",
        "solver_2 = LogisticRegression(max_iter=200, random_state=1, solver='liblinear', penalty='l1', fit_intercept= True)\n"
      ],
      "metadata": {
        "id": "cJAL3BMXZlpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating and fitting logistic regression grid\n",
        "model_2 = skl_ms.GridSearchCV(estimator=solver_2, param_grid = grid_logReg_2 )\n",
        "\n",
        "model_2.fit(X_train_norm,Y_train_np)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1pcHcLzacUn",
        "outputId": "cb337856-ad3c-4513-e09f-6e752079427b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(estimator=LogisticRegression(max_iter=200, penalty='l1',\n",
              "                                          random_state=1, solver='liblinear'),\n",
              "             param_grid={'C': array([69.        , 69.12244898, 69.24489796, 69.36734694, 69.48979592,\n",
              "       69.6122449 , 69.73469388, 69.85714286, 69.97959184, 70.10204082,\n",
              "       70.2244898 , 70.34693878, 70.46938776, 70.59183673, 70.71428571,\n",
              "       70.83673469, 70.95918367, 71.08163265, 71.20408163, 71.326...\n",
              "       72.06122449, 72.18367347, 72.30612245, 72.42857143, 72.55102041,\n",
              "       72.67346939, 72.79591837, 72.91836735, 73.04081633, 73.16326531,\n",
              "       73.28571429, 73.40816327, 73.53061224, 73.65306122, 73.7755102 ,\n",
              "       73.89795918, 74.02040816, 74.14285714, 74.26530612, 74.3877551 ,\n",
              "       74.51020408, 74.63265306, 74.75510204, 74.87755102, 75.        ]),\n",
              "                         'intercept_scaling': array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. , 1.1, 1.2, 1.3,\n",
              "       1.4, 1.5, 1.6, 1.7, 1.8, 1.9, 2. ])})"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ouput best parameters\n",
        "print('Best Score :', model_2.best_score_)\n",
        "print('Best Parameters :',model_2.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAOMeF0-a90I",
        "outputId": "9630954e-ed1a-4358-cfb2-b7edfb320326"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Score : 0.8707132735002361\n",
            "Best Parameters : {'C': 70.59183673469387, 'intercept_scaling': 0.8999999999999999}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# setting parameter variables using results from gridsearch\n",
        "para_C = model_2.best_params_['C']\n",
        "para_int_scale = model_2.best_params_['intercept_scaling']"
      ],
      "metadata": {
        "id": "ocbwq7p2ev0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predicting 'Lead' column from model"
      ],
      "metadata": {
        "id": "GaSUADFX7iSJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# using optimised parameter values to define new model for using on test data\n",
        "final_solver = LogisticRegression(max_iter=200, random_state=1, solver='liblinear', penalty=para_penalty, fit_intercept= para_intercept , C = para_C )"
      ],
      "metadata": {
        "id": "KnYY5HBzdk74"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fitting and predicting value of 'Lead' for test data\n",
        "final_solver.fit(X_train_norm,Y_train_np)\n",
        "\n",
        "Y_pred=final_solver.predict(X_test_norm)"
      ],
      "metadata": {
        "id": "VytM44lNtGaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Getting confusion matrix"
      ],
      "metadata": {
        "id": "VAlNHMjL7mP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnf_matrix = metrics.confusion_matrix(Y_test, Y_pred)\n",
        "print(cnf_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVMq8EPPDGEd",
        "outputId": "92212bd1-ff40-4cc2-d71d-bd12584e25af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 44  26]\n",
            " [ 12 230]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "calculating accuracy"
      ],
      "metadata": {
        "id": "Ov3QZXYj7p6S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = metrics.accuracy_score(Y_test, Y_pred)\n",
        "print(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mm8TmpZZJt8H",
        "outputId": "fd5fbec8-d18a-4680-9cf0-9d572e6ad0c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8782051282051282\n"
          ]
        }
      ]
    }
  ]
}